# HSL Stock Trading System - ì„œë²„ ë¦¬ì†ŒìŠ¤ ë° GPU ë¶„ì„

**ìƒì„±ì¼**: 2025-10-08
**ë¬¸ì„œ ìœ í˜•**: ì•„í‚¤í…ì²˜ ë¶„ì„
**ê´€ë ¨ ë¬¸ì„œ**: [ìš´ì˜ì„œë²„ë¶„ì‚°ì•„í‚¤í…ì²˜-ê°œë°œ-20251007.md](ìš´ì˜ì„œë²„ë¶„ì‚°ì•„í‚¤í…ì²˜-ê°œë°œ-20251007.md)

---

## 1. ê°œìš”

3ëŒ€ ì„œë²„(192.168.219.101~103) ë¶„ì‚° ë°°í¬ ì‹œìŠ¤í…œì˜ ë…¸ë“œë³„ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ë° GPU í™œìš© ë°©ì•ˆì„ ë¶„ì„í•œ ë¬¸ì„œì…ë‹ˆë‹¤.

---

## 2. ë…¸ë“œë³„ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ë¶„ì„

### 2.1 ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ìˆœìœ„

| ìˆœìœ„ | ë…¸ë“œ | IP | CPU | Memory | Storage | ì£¼ìš” ë³‘ëª© |
|------|------|-----|-----|--------|---------|-----------|
| 1ìœ„ ğŸ”´ | **Database Server** | 192.168.219.103 | 8 Core | **32GB** | **500GB NVMe** | **I/O, Memory** |
| 2ìœ„ ğŸŸ¡ | **Backend Server** | 192.168.219.102 | 8 Core | 16GB | 200GB | **CPU, Memory** |
| 3ìœ„ ğŸŸ¢ | **Scheduler Server** | 192.168.219.101 | 4 Core | 8GB | 100GB | ë‚®ìŒ |

---

### 2.2 Database Server (192.168.219.103) - ìµœê³  ë¦¬ì†ŒìŠ¤

**ì—­í• **: ë°ì´í„° ì €ì¥ ë° ê´€ë¦¬

**êµ¬ì„± ìš”ì†Œ**:
- PostgreSQL (TimescaleDB) - ì‹œê³„ì—´ ë°ì´í„° ì§‘ì•½
- Redis - ìºì‹œ ë° Celery ë¸Œë¡œì»¤
- InfluxDB - ë©”íŠ¸ë¦­ ì €ì¥

**ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­**:
```
CPU:     8 Core (ê¶Œì¥)
Memory:  32GB  (ëŒ€ìš©ëŸ‰ ë°ì´í„° ìºì‹±)
Storage: 500GB NVMe SSD (ë†’ì€ IOPS í•„ìš”)
```

**ì£¼ìš” ë³‘ëª©**:
- **I/O ì„±ëŠ¥**: ëŒ€ëŸ‰ì˜ ì‹œê³„ì—´ ë°ì´í„° ì½ê¸°/ì“°ê¸°
- **ë©”ëª¨ë¦¬**: PostgreSQL ì¿¼ë¦¬ ìºì‹œ, Redis ë°ì´í„°
- **ë””ìŠ¤í¬**: KOSPI ì „ì¢…ëª© Ã— 5ë…„ ë°ì´í„°

**ìµœì í™” ë°©ì•ˆ**:
- NVMe SSD ì‚¬ìš© (SATA SSD ëŒ€ë¹„ 5ë°° ì´ìƒ ì„±ëŠ¥)
- PostgreSQL shared_buffers: 8GB
- Redis maxmemory: 4GB
- ì¸ë±ìŠ¤ ìµœì í™”

---

### 2.3 Backend Server (192.168.219.102) - ì¤‘ê°„ ë¦¬ì†ŒìŠ¤

**ì—­í• **: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬ ë° ì‘ì—… ì‹¤í–‰

**êµ¬ì„± ìš”ì†Œ**:
- FastAPI - REST API ì„œë¹„ìŠ¤
- Celery Worker - ë¹„ë™ê¸° ì‘ì—… (ë°ì´í„° ìˆ˜ì§‘, ì§€í‘œ ê³„ì‚°)
- Celery Beat - ì •ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
- Nginx - ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ

**ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­**:
```
CPU:     8 Core (ê³ ë¶€í•˜ ê³„ì‚° ì²˜ë¦¬)
Memory:  16GB  (ë‹¤ì¤‘ Worker ìš´ì˜)
Storage: 200GB (ì½”ë“œ, ë¡œê·¸, ì„ì‹œ íŒŒì¼)
```

**ì£¼ìš” ë³‘ëª©**:
- **CPU**: ê¸°ìˆ  ì§€í‘œ ê³„ì‚° (RSI, MA, ë³¼ë¦°ì €ë°´ë“œ ë“±)
- **ë©”ëª¨ë¦¬**: Celery Worker ë‹¤ì¤‘ í”„ë¡œì„¸ìŠ¤
- **ë„¤íŠ¸ì›Œí¬**: API íŠ¸ë˜í”½, DB ì¿¼ë¦¬

**ìµœì í™” ë°©ì•ˆ**:
- Celery Worker ë™ì‹œì„±: 4-8
- FastAPI Worker: 4
- NumPy/Pandas ë²¡í„°í™” ì—°ì‚°

---

### 2.4 Scheduler Server (192.168.219.101) - ìµœì†Œ ë¦¬ì†ŒìŠ¤ â­

**ì—­í• **: ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ë° ì‹œê°í™”

**êµ¬ì„± ìš”ì†Œ**:
- Airflow Webserver - DAG ê´€ë¦¬ UI
- Airflow Scheduler - ì‘ì—… ìŠ¤ì¼€ì¤„ë§
- Grafana - ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- Nginx - ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ

**ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­**:
```
CPU:     4 Core (ìµœì†Œ)
Memory:  8GB   (ìµœì†Œ)
Storage: 100GB (ìµœì†Œ)
```

**ì£¼ìš” íŠ¹ì§•**:
- ì‹¤ì œ ë°ì´í„° ì²˜ë¦¬ë¥¼ í•˜ì§€ ì•ŠìŒ
- ì£¼ë¡œ ìŠ¤ì¼€ì¤„ë§ ë° ì¡°íšŒ ì‘ì—…
- ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì´ ê°€ì¥ ë‚®ìŒ

**ìµœì í™” ë°©ì•ˆ**:
- Airflow LocalExecutor ì‚¬ìš©
- Grafana ì¿¼ë¦¬ ìºì‹±
- ì •ì  íŒŒì¼ Nginx ìºì‹±

---

## 3. GPU í™œìš© ë°©ì•ˆ

### 3.1 GPU ê¶Œì¥ ë…¸ë“œ: Backend Server (192.168.219.102) ğŸ’

**Backend Serverì— GPUë¥¼ ì¶”ì²œí•˜ëŠ” ì´ìœ **:

#### 3.1.1 í˜„ì¬ ì‘ì—…ì—ì„œì˜ GPU í™œìš©

**ëŒ€ëŸ‰ ì§€í‘œ ê³„ì‚° ê°€ì†**:
```python
# CPU ê¸°ë°˜ (í˜„ì¬)
import pandas as pd
import numpy as np

# GPU ê°€ì† (ì „í™˜ í›„)
import cudf  # GPU DataFrame
import cupy as cp  # GPU NumPy

# ì„±ëŠ¥ í–¥ìƒ: 10~50ë°°
```

**ë³‘ë ¬ ì‘ì—… ì²˜ë¦¬**:
- KOSPI ì „ì¢…ëª© (ì•½ 800ì¢…ëª©) ë™ì‹œ ë¶„ì„
- 5ë…„ê°„ ì¼ë´‰ ë°ì´í„° (1,250ì¼) Ã— 800ì¢…ëª© = 100ë§Œ í–‰
- GPU ë³‘ë ¬ ì—°ì‚°ìœ¼ë¡œ ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶•

**ë°±í…ŒìŠ¤íŒ… ê°€ì†**:
```python
# ì „ëµ ì‹œë®¬ë ˆì´ì…˜
- 100ê°œ ì „ëµ Ã— 800ì¢…ëª© Ã— 5ë…„ ë°ì´í„°
- CPU: ìˆ˜ ì‹œê°„ ì†Œìš”
- GPU: ìˆ˜ ë¶„ ë‚´ ì™„ë£Œ
```

---

#### 3.1.2 í–¥í›„ í™•ì¥ ê°€ëŠ¥ì„± ğŸš€

**ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ**:
```python
# ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸
- LSTM (Long Short-Term Memory)
- Transformer ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡
- í›ˆë ¨ ì‹œê°„: GPUë¡œ 10~100ë°° ë‹¨ì¶•
```

**ì‹¤ì‹œê°„ íŒ¨í„´ ì¸ì‹**:
```python
# ì°¨íŠ¸ íŒ¨í„´ ìë™ íƒì§€
- í—¤ë“œì•¤ìˆ„ë”, ì‚¼ê°ìˆ˜ë ´ ë“±
- CNN ê¸°ë°˜ ì´ë¯¸ì§€ ì¸ì‹
- GPU ì‹¤ì‹œê°„ ì¶”ë¡ 
```

**ê°•í™”í•™ìŠµ íŠ¸ë ˆì´ë”© ë´‡**:
```python
# Deep Q-Network (DQN)
- ìë™ ë§¤ë§¤ ì „ëµ í•™ìŠµ
- GPU ë³‘ë ¬ ì‹œë®¬ë ˆì´ì…˜
- ìˆ˜ë°±ë§Œ ì—í”¼ì†Œë“œ í•™ìŠµ
```

**ëŒ€ê·œëª¨ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”**:
```python
# ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
- 100ë§Œ íšŒ ì‹œë®¬ë ˆì´ì…˜
- CPU: ìˆ˜ ì‹œê°„
- GPU: ìˆ˜ ë¶„
```

---

#### 3.1.3 ì ìš© ê°€ëŠ¥í•œ GPU ê°€ì† ë¼ì´ë¸ŒëŸ¬ë¦¬

| ê¸°ì¡´ (CPU) | GPU ê°€ì† ë²„ì „ | ì„±ëŠ¥ í–¥ìƒ |
|------------|---------------|-----------|
| NumPy | CuPy | 10~50ë°° |
| Pandas | cuDF (RAPIDS) | 5~20ë°° |
| Scikit-learn | cuML (RAPIDS) | 10~50ë°° |
| - | PyTorch / TensorFlow | ë”¥ëŸ¬ë‹ |
| TA-Lib | GPU ìµœì í™” ë²„ì „ | 5~10ë°° |

**RAPIDS AI ìƒíƒœê³„**:
```python
import cudf  # GPU DataFrame
import cuml  # GPU ë¨¸ì‹ ëŸ¬ë‹
import cugraph  # GPU ê·¸ë˜í”„ ë¶„ì„

# ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ GPUì—ì„œ ì‹¤í–‰
```

---

### 3.2 GPU ê¶Œì¥ ì‚¬ì–‘

#### ìµœì†Œ ì‚¬ì–‘ (ë°±í…ŒìŠ¤íŒ…, ê¸°ë³¸ ì§€í‘œ ê³„ì‚°)
```
ëª¨ë¸:  NVIDIA GTX 1660 Ti
VRAM:  6GB
ê°€ê²©:  ì•½ 30ë§Œì› (ì¤‘ê³ )
ìš©ë„:  ê¸°ìˆ  ì§€í‘œ ê³„ì‚° ê°€ì†, ê¸°ë³¸ ë°±í…ŒìŠ¤íŒ…
```

#### ê¶Œì¥ ì‚¬ì–‘ (ë¨¸ì‹ ëŸ¬ë‹ í¬í•¨) â­
```
ëª¨ë¸:  NVIDIA RTX 3060 / RTX 4060
VRAM:  12GB
ê°€ê²©:  ì•½ 40~50ë§Œì›
ìš©ë„:
- ê¸°ìˆ  ì§€í‘œ ê³„ì‚°
- ë°±í…ŒìŠ¤íŒ…
- LSTM/Transformer ëª¨ë¸ í•™ìŠµ
- ì‹¤ì‹œê°„ ì¶”ë¡ 
```

#### ê³ ê¸‰ ì‚¬ì–‘ (ëŒ€ê·œëª¨ ë”¥ëŸ¬ë‹)
```
ëª¨ë¸:  NVIDIA RTX 4070 / A4000
VRAM:  16GB
ê°€ê²©:  ì•½ 80~100ë§Œì›
ìš©ë„:
- ëŒ€ê·œëª¨ ë”¥ëŸ¬ë‹ ëª¨ë¸
- ì‹¤ì‹œê°„ ê³ ì† ì¶”ë¡ 
- ë³µì¡í•œ ê°•í™”í•™ìŠµ
```

---

### 3.3 Database Serverì—ëŠ” GPU ë¶ˆí•„ìš”

**Database Serverì˜ ì‘ì—… íŠ¹ì„±**:
- PostgreSQL, Redis, InfluxDB â†’ **CPU ê¸°ë°˜ I/O ì‘ì—…**
- GPU í™œìš©ë„ ê±°ì˜ ì—†ìŒ
- **NVMe SSD**ê°€ í›¨ì”¬ ì¤‘ìš”

**ë¦¬ì†ŒìŠ¤ ìš°ì„ ìˆœìœ„**:
1. **NVMe SSD** (ê°€ì¥ ì¤‘ìš”)
2. **ëŒ€ìš©ëŸ‰ ë©”ëª¨ë¦¬** (32GB+)
3. CPU ì½”ì–´ ìˆ˜ (8 Core)
4. ~~GPU~~ (ë¶ˆí•„ìš”)

---

### 3.4 Scheduler Serverì—ë„ GPU ë¶ˆí•„ìš”

**Scheduler Serverì˜ ì‘ì—… íŠ¹ì„±**:
- Airflow: ìŠ¤ì¼€ì¤„ë§ (ê²½ëŸ‰ ì‘ì—…)
- Grafana: ëŒ€ì‹œë³´ë“œ ì¡°íšŒ (ì£¼ë¡œ ì½ê¸°)
- GPU í™œìš©ë„ ì—†ìŒ

---

## 4. ìµœì¢… ê¶Œì¥ êµ¬ì„±

### 4.1 ë¦¬ì†ŒìŠ¤ í• ë‹¹ ì „ëµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scheduler (101) - ìµœì†Œ ë¦¬ì†ŒìŠ¤                          â”‚
â”‚  â”œâ”€â”€ CPU: 4 Core                                        â”‚
â”‚  â”œâ”€â”€ Memory: 8GB                                        â”‚
â”‚  â””â”€â”€ Storage: 100GB SSD                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Backend (102) - ì¤‘ê°„ ë¦¬ì†ŒìŠ¤ + GPU â­                   â”‚
â”‚  â”œâ”€â”€ CPU: 8 Core                                        â”‚
â”‚  â”œâ”€â”€ Memory: 16GB                                       â”‚
â”‚  â”œâ”€â”€ Storage: 200GB SSD                                 â”‚
â”‚  â””â”€â”€ GPU: RTX 3060 (12GB) - ì„ íƒì‚¬í•­                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Database (103) - ìµœëŒ€ ë¦¬ì†ŒìŠ¤ + NVMe                    â”‚
â”‚  â”œâ”€â”€ CPU: 8 Core                                        â”‚
â”‚  â”œâ”€â”€ Memory: 32GB                                       â”‚
â”‚  â””â”€â”€ Storage: 500GB NVMe SSD â­                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 4.2 ë‹¨ê³„ë³„ ë„ì… ì „ëµ

#### Phase 1: ê¸°ë³¸ êµ¬ì„± (í•„ìˆ˜)
```
101 (Scheduler):  CPU 4C + 8GB RAM + 100GB SSD
102 (Backend):    CPU 8C + 16GB RAM + 200GB SSD
103 (Database):   CPU 8C + 32GB RAM + 500GB NVMe â­
```
**ì˜ˆì‚°**: ì•½ 200~300ë§Œì› (ì„œë²„ í•˜ë“œì›¨ì–´ ê¸°ì¤€)

---

#### Phase 2: GPU ì¶”ê°€ (ì„ íƒì‚¬í•­)
```
102 (Backend) + RTX 3060 (12GB)
```
**ì¶”ê°€ ì˜ˆì‚°**: ì•½ 40~50ë§Œì›
**íš¨ê³¼**: ë°±í…ŒìŠ¤íŒ… 10~50ë°° ê°€ì†

---

#### Phase 3: ë¨¸ì‹ ëŸ¬ë‹ í™•ì¥ (í–¥í›„)
```
102 (Backend) GPU ì—…ê·¸ë ˆì´ë“œ
- RTX 3060 â†’ RTX 4070 (16GB)
- ë˜ëŠ” ì¶”ê°€ Backend ì„œë²„ (GPU ì „ìš©)
```
**ì¶”ê°€ ì˜ˆì‚°**: ì•½ 80~100ë§Œì›
**íš¨ê³¼**: ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥

---

### 4.3 ì˜ˆì‚° ì œì•½ ì‹œ ìš°ì„ ìˆœìœ„

#### ìµœìš°ì„  (í•„ìˆ˜)
1. **Database Server NVMe SSD** (500GB)
2. **Database Server ë©”ëª¨ë¦¬** (32GB)
3. **Backend Server CPU** (8 Core)

#### ì°¨ìˆœìœ„ (ê¶Œì¥)
4. Backend Server ë©”ëª¨ë¦¬ (16GB)
5. Database Server CPU (8 Core)
6. Scheduler Server (ê¸°ë³¸ ì‚¬ì–‘)

#### ì„ íƒì‚¬í•­ (í–¥í›„ ì¶”ê°€ ê°€ëŠ¥)
7. **Backend Server GPU** (RTX 3060)

---

## 5. GPU í™œìš© ì˜ˆì‹œ ì½”ë“œ

### 5.1 ê¸°ìˆ  ì§€í‘œ ê³„ì‚° ê°€ì†

```python
# Before (CPU)
import pandas as pd
import numpy as np

def calculate_rsi_cpu(df, period=14):
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

# 800ì¢…ëª© Ã— 1,250ì¼ ì²˜ë¦¬ ì‹œê°„: ì•½ 5ë¶„

# After (GPU)
import cudf
import cupy as cp

def calculate_rsi_gpu(df, period=14):
    # cuDFëŠ” GPUì—ì„œ Pandasì™€ ë™ì¼í•œ API ì œê³µ
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    return rsi

# 800ì¢…ëª© Ã— 1,250ì¼ ì²˜ë¦¬ ì‹œê°„: ì•½ 10ì´ˆ
# ì„±ëŠ¥ í–¥ìƒ: 30ë°°
```

---

### 5.2 ë°±í…ŒìŠ¤íŒ… ê°€ì†

```python
# Before (CPU)
def backtest_strategy_cpu(stock_data, strategy):
    results = []
    for stock in stock_data:  # ìˆœì°¨ ì²˜ë¦¬
        result = strategy.run(stock)
        results.append(result)
    return results

# 100ì „ëµ Ã— 800ì¢…ëª© ì²˜ë¦¬ ì‹œê°„: ì•½ 2ì‹œê°„

# After (GPU)
import cupy as cp

def backtest_strategy_gpu(stock_data, strategy):
    # GPU ë³‘ë ¬ ì²˜ë¦¬
    stock_array = cp.array(stock_data)
    results = cp.apply_along_axis(strategy.run, 1, stock_array)
    return results.get()  # GPU -> CPU ì „ì†¡

# 100ì „ëµ Ã— 800ì¢…ëª© ì²˜ë¦¬ ì‹œê°„: ì•½ 3ë¶„
# ì„±ëŠ¥ í–¥ìƒ: 40ë°°
```

---

### 5.3 ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ (í–¥í›„)

```python
# PyTorch ì‚¬ìš© (GPU ìë™ ê°ì§€)
import torch
import torch.nn as nn

class StockPricePredictor(nn.Module):
    def __init__(self):
        super().__init__()
        self.lstm = nn.LSTM(input_size=10, hidden_size=50, num_layers=2)
        self.fc = nn.Linear(50, 1)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        prediction = self.fc(lstm_out[-1])
        return prediction

# GPU ì‚¬ìš© ì„¤ì •
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = StockPricePredictor().to(device)

# í›ˆë ¨
# CPU: 10ì‹œê°„ â†’ GPU: 30ë¶„
# ì„±ëŠ¥ í–¥ìƒ: 20ë°°
```

---

## 6. íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ ë¶„ì„

### 6.1 ROI ê³„ì‚°

| íˆ¬ì í•­ëª© | ë¹„ìš© | íš¨ê³¼ | ROI |
|-----------|------|------|-----|
| **NVMe SSD (500GB)** | 10ë§Œì› | I/O 3ë°° í–¥ìƒ | â­â­â­â­â­ |
| **ë©”ëª¨ë¦¬ 32GB** | 15ë§Œì› | ì¿¼ë¦¬ ì„±ëŠ¥ 2ë°° | â­â­â­â­â­ |
| **GPU RTX 3060** | 50ë§Œì› | ê³„ì‚° 30ë°° í–¥ìƒ | â­â­â­â­ |
| **GPU RTX 4070** | 100ë§Œì› | ë”¥ëŸ¬ë‹ ê°€ëŠ¥ | â­â­â­ (í–¥í›„) |

---

### 6.2 ë‹¨ê³„ë³„ ì˜ˆì‚° ë° íš¨ê³¼

#### Stage 1: ê¸°ë³¸ êµ¬ì„± (í•„ìˆ˜)
```
ì˜ˆì‚°: 200ë§Œì›
íš¨ê³¼: ì•ˆì •ì ì¸ ë¶„ì‚° ì‹œìŠ¤í…œ êµ¬ì¶•
```

#### Stage 2: GPU ì¶”ê°€ (ê¶Œì¥)
```
ì¶”ê°€ ì˜ˆì‚°: 50ë§Œì› (RTX 3060)
íš¨ê³¼: ë°±í…ŒìŠ¤íŒ… 30ë°° ê°€ì†
ì´ ì˜ˆì‚°: 250ë§Œì›
```

#### Stage 3: ê³ ê¸‰ GPU (ì„ íƒ)
```
ì¶”ê°€ ì˜ˆì‚°: 50ë§Œì› (3060â†’4070 ì—…ê·¸ë ˆì´ë“œ)
íš¨ê³¼: ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥
ì´ ì˜ˆì‚°: 300ë§Œì›
```

---

## 7. ê²°ë¡ 

### 7.1 ìµœì¢… ê¶Œì¥ì‚¬í•­

1. **ê°€ì¥ ìì›ì„ ì ê²Œ ì‚¬ìš©í•˜ëŠ” ë…¸ë“œ**: **Scheduler Server (101)** âœ…
   - CPU 4 Core, 8GB RAM, 100GB SSD

2. **GPUê°€ í•„ìš”í•œ ë…¸ë“œ**: **Backend Server (102)** âœ…
   - í˜„ì¬: ê¸°ìˆ  ì§€í‘œ ê³„ì‚°, ë°±í…ŒìŠ¤íŒ… ê°€ì†
   - í–¥í›„: ë¨¸ì‹ ëŸ¬ë‹, ì‹¤ì‹œê°„ ì¶”ë¡ 

3. **GPU ë¶ˆí•„ìš”í•œ ë…¸ë“œ**: Database (103), Scheduler (101)
   - DatabaseëŠ” NVMe SSDê°€ í›¨ì”¬ ì¤‘ìš”
   - SchedulerëŠ” ê²½ëŸ‰ ì‘ì—…ë§Œ ìˆ˜í–‰

---

### 7.2 ì‹¤ì „ ê°€ì´ë“œ

#### GPU ì—†ì´ ì‹œì‘í•˜ëŠ” ê²½ìš°
```
1. ê¸°ë³¸ 3ëŒ€ ì„œë²„ êµ¬ì¶•
2. ì„±ëŠ¥ ë³‘ëª© ì§€ì  ëª¨ë‹ˆí„°ë§
3. í•„ìš” ì‹œ Backend ì„œë²„ì— GPU ì¶”ê°€
```

#### GPU í¬í•¨ ì‹œì‘í•˜ëŠ” ê²½ìš°
```
1. Backend ì„œë²„ì— RTX 3060 ì„¤ì¹˜
2. CUDA Toolkit ì„¤ì¹˜
3. RAPIDS AI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
4. ê¸°ì¡´ ì½”ë“œ GPU ë²„ì „ìœ¼ë¡œ ì ì§„ì  ì „í™˜
```

---

### 7.3 ì°¸ê³  ì‚¬í•­

**GPUëŠ” ì„ íƒì‚¬í•­ì…ë‹ˆë‹¤**:
- í˜„ì¬ ì‹œìŠ¤í…œì€ CPUë§Œìœ¼ë¡œë„ ì¶©ë¶„íˆ ë™ì‘
- ì„±ëŠ¥ ê°œì„ ì´ í•„ìš”í•  ë•Œ ì¶”ê°€ ê°€ëŠ¥
- ë¨¸ì‹ ëŸ¬ë‹ ë„ì… ì‹œ í•„ìˆ˜

**íˆ¬ì ìš°ì„ ìˆœìœ„**:
1. Database Server NVMe SSD (ê°€ì¥ ì¤‘ìš”)
2. Database Server ë©”ëª¨ë¦¬ 32GB
3. Backend Server GPU (ì„ íƒì‚¬í•­, í–¥í›„ ì¶”ê°€ ê°€ëŠ¥)

---

## ë¶€ë¡ A: GPU ì„¤ì¹˜ ë° ì„¤ì • ê°€ì´ë“œ

### A.1 NVIDIA GPU ë“œë¼ì´ë²„ ì„¤ì¹˜ (Rocky Linux)

```bash
# Rocky Linux 9ì—ì„œ NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜
sudo dnf config-manager --add-repo=https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/cuda-rhel9.repo
sudo dnf install -y nvidia-driver nvidia-settings
sudo dnf install -y cuda-toolkit-12-3

# ì¬ë¶€íŒ…
sudo reboot

# ì„¤ì¹˜ í™•ì¸
nvidia-smi
```

---

### A.2 Docker GPU ì§€ì› ì„¤ì •

```bash
# NVIDIA Container Toolkit ì„¤ì¹˜
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \
  sudo tee /etc/yum.repos.d/nvidia-docker.repo

sudo dnf install -y nvidia-container-toolkit
sudo systemctl restart docker

# Docker Composeì—ì„œ GPU ì‚¬ìš©
# docker-compose.yml
services:
  backend:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

---

### A.3 RAPIDS AI ì„¤ì¹˜ (GPU ê°€ì† ë¼ì´ë¸ŒëŸ¬ë¦¬)

```bash
# Conda í™˜ê²½ì—ì„œ ì„¤ì¹˜
conda create -n rapids-env python=3.10
conda activate rapids-env

# RAPIDS ì„¤ì¹˜ (CUDA 12.0)
conda install -c rapidsai -c conda-forge -c nvidia \
    cudf=23.10 cuml=23.10 cugraph=23.10 \
    cudatoolkit=12.0
```

---

### A.4 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸

```python
# GPU vs CPU ì„±ëŠ¥ ë¹„êµ
import time
import pandas as pd
import cudf
import numpy as np
import cupy as cp

# ìƒ˜í”Œ ë°ì´í„° ìƒì„±
n_rows = 1_000_000
data = {
    'close': np.random.randn(n_rows),
    'volume': np.random.randint(1000, 100000, n_rows)
}

# CPU ë²¤ì¹˜ë§ˆí¬
df_cpu = pd.DataFrame(data)
start = time.time()
result_cpu = df_cpu['close'].rolling(window=20).mean()
cpu_time = time.time() - start

# GPU ë²¤ì¹˜ë§ˆí¬
df_gpu = cudf.DataFrame(data)
start = time.time()
result_gpu = df_gpu['close'].rolling(window=20).mean()
gpu_time = time.time() - start

print(f"CPU ì‹œê°„: {cpu_time:.4f}ì´ˆ")
print(f"GPU ì‹œê°„: {gpu_time:.4f}ì´ˆ")
print(f"ì„±ëŠ¥ í–¥ìƒ: {cpu_time/gpu_time:.2f}ë°°")
```

---

## ë¶€ë¡ B: ê´€ë ¨ ë¬¸ì„œ

- [ìš´ì˜ì„œë²„ë¶„ì‚°ì•„í‚¤í…ì²˜-ê°œë°œ-20251007.md](ìš´ì˜ì„œë²„ë¶„ì‚°ì•„í‚¤í…ì²˜-ê°œë°œ-20251007.md) - 3ëŒ€ ì„œë²„ ë¶„ì‚° ì•„í‚¤í…ì²˜
- [ì‹œìŠ¤í…œì•„í‚¤í…ì²˜-ê°œë°œ-20251007.md](ì‹œìŠ¤í…œì•„í‚¤í…ì²˜-ê°œë°œ-20251007.md) - ì „ì²´ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-10-08
**ì‘ì„±ì**: HSL Project Team
**ê²€í†  ìƒíƒœ**: ì´ˆì•ˆ
