# HSL Stock Trading System - 운영서버 이관 계획서

## 1. 이관 개요

### 1.1 프로젝트 정보
- **프로젝트명**: HSL Stock Trading System 운영서버 이관
- **이관 일정**: 2025년 10월 7일 ~ 10월 14일 (7일간)
- **담당자**: 시스템 관리자
- **이관 방식**: 단계적 이관 (Phased Migration)

### 1.2 이관 목표
- 단일 개발 PC에서 3대의 Rocky Linux 서버로 시스템 분산
- 서비스 중단 최소화 (목표: 30분 이내)
- 데이터 무결성 보장
- 성능 및 안정성 향상

### 1.3 서버 정보
| 구분 | IP | OS | 역할 | 상태 |
|------|----|----|------|------|
| 개발 PC | 192.168.219.100 | Windows | 현재 운영 중 | Active |
| Scheduler Server | 192.168.219.101 | Rocky Linux 9 | Airflow, Grafana | Ready |
| Backend Server | 192.168.219.102 | Rocky Linux 9 | API, Worker | Ready |
| Database Server | 192.168.219.103 | Rocky Linux 9 | DB, Cache | Ready |

## 2. 사전 준비 사항

### 2.1 인프라 준비 ✅
- [x] Rocky Linux 9 설치 (3대)
- [x] 네트워크 설정 및 통신 확인
- [x] Nginx 설치
- [ ] Docker 및 Docker Compose 설치
- [ ] 필요 패키지 설치
- [ ] 방화벽 설정

### 2.2 백업
```bash
# 개발 PC에서 실행
# PostgreSQL 전체 백업
docker exec stock-db pg_dumpall -U admin > backup_$(date +%Y%m%d).sql

# Redis 데이터 백업
docker exec stock-redis redis-cli SAVE
docker cp stock-redis:/data/dump.rdb ./backup/redis_$(date +%Y%m%d).rdb

# InfluxDB 백업
docker exec stock-influxdb influx backup /backup -t my-super-secret-auth-token
docker cp stock-influxdb:/backup ./backup/influxdb_$(date +%Y%m%d)

# 소스 코드 백업
tar -czf stock-trading-system_$(date +%Y%m%d).tar.gz stock-trading-system/
```

### 2.3 도구 준비
- SSH 클라이언트 (PuTTY 또는 터미널)
- SCP/SFTP 도구 (파일 전송)
- 데이터베이스 클라이언트 (DBeaver, pgAdmin)
- 모니터링 도구

## 3. 이관 일정

### Phase 0: 준비 단계 (Day 1: 10/7)
| 시간 | 작업 | 담당자 | 비고 |
|------|------|--------|------|
| 09:00-10:00 | 전체 시스템 백업 | 관리자 | |
| 10:00-12:00 | 서버 기본 설정 | 관리자 | Docker, 패키지 설치 |
| 13:00-15:00 | 네트워크 및 보안 설정 | 관리자 | 방화벽, SSH |
| 15:00-17:00 | 테스트 환경 구성 | 관리자 | |

### Phase 1: Database Server 이관 (Day 2-3: 10/8-9)
| 시간 | 작업 | 담당자 | 비고 |
|------|------|--------|------|
| Day 2 09:00-12:00 | PostgreSQL 설치 및 설정 | DBA | |
| Day 2 13:00-17:00 | 데이터 마이그레이션 | DBA | |
| Day 3 09:00-12:00 | Redis, InfluxDB 설치 | DBA | |
| Day 3 13:00-17:00 | 연결 테스트 | DBA | |

### Phase 2: Backend Server 이관 (Day 4-5: 10/10-11)
| 시간 | 작업 | 담당자 | 비고 |
|------|------|--------|------|
| Day 4 09:00-12:00 | Backend 애플리케이션 배포 | 개발자 | |
| Day 4 13:00-17:00 | Celery Worker/Beat 설정 | 개발자 | |
| Day 5 09:00-12:00 | API 테스트 | 개발자 | |
| Day 5 13:00-17:00 | 성능 테스트 | 개발자 | |

### Phase 3: Scheduler Server 이관 (Day 6: 10/12)
| 시간 | 작업 | 담당자 | 비고 |
|------|------|--------|------|
| 09:00-12:00 | Airflow 설치 및 설정 | 관리자 | |
| 13:00-15:00 | Grafana 설치 및 대시보드 | 관리자 | |
| 15:00-17:00 | 통합 테스트 | 관리자 | |

### Phase 4: 전환 및 검증 (Day 7: 10/14)
| 시간 | 작업 | 담당자 | 비고 |
|------|------|--------|------|
| 09:00-10:00 | 최종 데이터 동기화 | 전체 | **서비스 중단** |
| 10:00-11:00 | DNS/라우팅 전환 | 네트워크 | |
| 11:00-12:00 | 서비스 검증 | 전체 | |
| 13:00-17:00 | 모니터링 및 안정화 | 전체 | |

## 4. 상세 이관 절차

### 4.1 Database Server (192.168.219.103) 구성

#### Step 1: 서버 접속 및 기본 설정
```bash
# SSH 접속
ssh root@192.168.219.103

# 시스템 업데이트
dnf update -y

# 시간대 설정
timedatectl set-timezone Asia/Seoul

# Docker 설치
dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
dnf install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin
systemctl start docker
systemctl enable docker

# 프로젝트 디렉토리 생성
mkdir -p /opt/stock-trading/database
cd /opt/stock-trading
```

#### Step 2: docker-compose.yml 생성
```bash
cat > /opt/stock-trading/docker-compose-db.yml << 'EOF'
version: '3.8'

services:
  postgres:
    image: timescale/timescaledb:latest-pg15
    container_name: stock-db
    environment:
      POSTGRES_DB: stocktrading
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - stock-network
    restart: always

  redis:
    image: redis:7-alpine
    container_name: stock-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - stock-network
    restart: always
    command: redis-server --appendonly yes

  influxdb:
    image: influxdb:2.7
    container_name: stock-influxdb
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: admin
      DOCKER_INFLUXDB_INIT_PASSWORD: admin123
      DOCKER_INFLUXDB_INIT_ORG: stocktrading
      DOCKER_INFLUXDB_INIT_BUCKET: metrics
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: my-super-secret-auth-token
    ports:
      - "8086:8086"
    volumes:
      - influxdb_data:/var/lib/influxdb2
    networks:
      - stock-network
    restart: always

volumes:
  postgres_data:
  redis_data:
  influxdb_data:

networks:
  stock-network:
    driver: bridge
EOF
```

#### Step 3: 데이터 복원
```bash
# 개발 PC에서 백업 파일 전송
scp backup_*.sql root@192.168.219.103:/opt/stock-trading/
scp redis_*.rdb root@192.168.219.103:/opt/stock-trading/

# Database Server에서 실행
docker-compose -f docker-compose-db.yml up -d

# PostgreSQL 데이터 복원
docker exec -i stock-db psql -U admin -d stocktrading < backup_20251007.sql

# Redis 데이터 복원
docker cp redis_20251007.rdb stock-redis:/data/dump.rdb
docker restart stock-redis
```

### 4.2 Backend Server (192.168.219.102) 구성

#### Step 1: 서버 설정 및 소스 코드 배포
```bash
# SSH 접속
ssh root@192.168.219.102

# Docker 설치 (위와 동일)
# ...

# 프로젝트 디렉토리 생성
mkdir -p /opt/stock-trading
cd /opt/stock-trading

# 소스 코드 전송 (개발 PC에서)
scp -r stock-trading-system/backend root@192.168.219.102:/opt/stock-trading/
scp -r stock-trading-system/frontend root@192.168.219.102:/opt/stock-trading/
```

#### Step 2: docker-compose.yml 생성
```bash
cat > /opt/stock-trading/docker-compose-backend.yml << 'EOF'
version: '3.8'

services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: stock-backend
    environment:
      DATABASE_URL: postgresql://admin:admin123@192.168.219.103:5432/stocktrading
      REDIS_URL: redis://192.168.219.103:6379
      CELERY_BROKER_URL: redis://192.168.219.103:6379/0
      CELERY_RESULT_BACKEND: redis://192.168.219.103:6379/0
      INFLUXDB_URL: http://192.168.219.103:8086
      INFLUXDB_TOKEN: my-super-secret-auth-token
      JWT_SECRET_KEY: your-secret-key-change-this
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./frontend:/app/static
    networks:
      - stock-network
    restart: always
    command: uvicorn main:app --host 0.0.0.0 --port 8000

  celery-worker:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: stock-celery-worker
    environment:
      DATABASE_URL: postgresql://admin:admin123@192.168.219.103:5432/stocktrading
      REDIS_URL: redis://192.168.219.103:6379
      CELERY_BROKER_URL: redis://192.168.219.103:6379/0
      CELERY_RESULT_BACKEND: redis://192.168.219.103:6379/0
    volumes:
      - ./backend:/app
    networks:
      - stock-network
    restart: always
    command: celery -A celery_app worker --loglevel=info

  celery-beat:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: stock-celery-beat
    environment:
      DATABASE_URL: postgresql://admin:admin123@192.168.219.103:5432/stocktrading
      REDIS_URL: redis://192.168.219.103:6379
      CELERY_BROKER_URL: redis://192.168.219.103:6379/0
      CELERY_RESULT_BACKEND: redis://192.168.219.103:6379/0
    volumes:
      - ./backend:/app
    networks:
      - stock-network
    restart: always
    command: celery -A celery_app beat --loglevel=info

  nginx:
    image: nginx:alpine
    container_name: stock-nginx-backend
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/backend.conf:/etc/nginx/nginx.conf:ro
      - ./frontend:/usr/share/nginx/html:ro
    networks:
      - stock-network
    restart: always

networks:
  stock-network:
    driver: bridge
EOF
```

#### Step 3: Nginx 설정
```bash
mkdir -p /opt/stock-trading/nginx
cat > /opt/stock-trading/nginx/backend.conf << 'EOF'
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    upstream backend {
        server stock-backend:8000;
    }

    server {
        listen 80;
        server_name 192.168.219.102;

        # 정적 파일
        location /static {
            alias /usr/share/nginx/html;
            try_files $uri $uri/ =404;
        }

        # API 프록시
        location /api {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # 기본 경로
        location / {
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
EOF
```

### 4.3 Scheduler Server (192.168.219.101) 구성

#### Step 1: 서버 설정
```bash
# SSH 접속
ssh root@192.168.219.101

# Docker 설치 (위와 동일)
# ...

# 프로젝트 디렉토리 생성
mkdir -p /opt/stock-trading
cd /opt/stock-trading

# Airflow 관련 파일 전송
scp -r stock-trading-system/airflow root@192.168.219.101:/opt/stock-trading/
scp -r stock-trading-system/monitoring root@192.168.219.101:/opt/stock-trading/
```

#### Step 2: docker-compose.yml 생성
```bash
cat > /opt/stock-trading/docker-compose-scheduler.yml << 'EOF'
version: '3.8'

services:
  airflow-webserver:
    image: apache/airflow:2.7.2
    container_name: stock-airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://admin:admin123@192.168.219.103:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://192.168.219.103:6379/0
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      _PIP_ADDITIONAL_REQUIREMENTS: 'pandas sqlalchemy psycopg2-binary requests beautifulsoup4'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    ports:
      - "8080:8080"
    networks:
      - stock-network
    restart: always
    command: airflow webserver

  airflow-scheduler:
    image: apache/airflow:2.7.2
    container_name: stock-airflow-scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://admin:admin123@192.168.219.103:5432/airflow
      AIRFLOW__CELERY__BROKER_URL: redis://192.168.219.103:6379/0
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      _PIP_ADDITIONAL_REQUIREMENTS: 'pandas sqlalchemy psycopg2-binary requests beautifulsoup4'
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    networks:
      - stock-network
    restart: always
    command: airflow scheduler

  grafana:
    image: grafana/grafana:10.2.0
    container_name: stock-grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin123
      GF_INSTALL_PLUGINS: grafana-clock-panel
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - stock-network
    restart: always

  nginx:
    image: nginx:alpine
    container_name: stock-nginx-scheduler
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/scheduler.conf:/etc/nginx/nginx.conf:ro
    networks:
      - stock-network
    restart: always

volumes:
  grafana_data:

networks:
  stock-network:
    driver: bridge
EOF
```

## 5. 검증 절차

### 5.1 Database Server 검증
```bash
# PostgreSQL 연결 테스트
psql -h 192.168.219.103 -U admin -d stocktrading -c "SELECT version();"

# Redis 연결 테스트
redis-cli -h 192.168.219.103 ping

# InfluxDB 상태 확인
curl http://192.168.219.103:8086/health
```

### 5.2 Backend Server 검증
```bash
# API Health Check
curl http://192.168.219.102:8000/health

# Celery Worker 상태
docker exec stock-celery-worker celery -A celery_app status

# 주가 데이터 조회 테스트
curl http://192.168.219.102:8000/api/stocks/list
```

### 5.3 Scheduler Server 검증
```bash
# Airflow 웹 UI 접속
curl -I http://192.168.219.101:8080

# Grafana 접속
curl -I http://192.168.219.101:3000

# DAG 상태 확인
docker exec stock-airflow-scheduler airflow dags list
```

### 5.4 통합 테스트
1. **데이터 수집 테스트**
   - 수동으로 데이터 수집 DAG 실행
   - 데이터베이스에 저장 확인

2. **API 통합 테스트**
   - 프론트엔드에서 API 호출
   - 실시간 데이터 조회

3. **모니터링 테스트**
   - Grafana 대시보드 정상 표시
   - 메트릭 수집 확인

## 6. 롤백 계획

### 6.1 롤백 기준
- 핵심 서비스 30분 이상 복구 불가
- 데이터 무결성 문제 발생
- 성능 심각한 저하 (응답시간 5배 이상)

### 6.2 롤백 절차
```bash
# Step 1: 신규 서버 서비스 중지
docker-compose -f docker-compose-db.yml down     # Database Server
docker-compose -f docker-compose-backend.yml down # Backend Server
docker-compose -f docker-compose-scheduler.yml down # Scheduler Server

# Step 2: 개발 PC 서비스 재시작
cd F:\hhstock\stock-trading-system
docker-compose up -d

# Step 3: DNS/라우팅 원복
# 클라이언트를 개발 PC로 다시 향하도록 설정

# Step 4: 검증
curl http://192.168.219.100:8000/health
```

## 7. 이관 후 작업

### 7.1 모니터링 강화 (Day 8-14)
- 24시간 집중 모니터링
- 성능 지표 수집 및 분석
- 에러 로그 분석

### 7.2 최적화
```bash
# PostgreSQL 튜닝
postgresql.conf 조정:
- shared_buffers = 8GB
- effective_cache_size = 24GB
- work_mem = 32MB
- maintenance_work_mem = 2GB

# Redis 최적화
redis.conf:
- maxmemory 4gb
- maxmemory-policy allkeys-lru
```

### 7.3 문서화
- 운영 매뉴얼 작성
- 트러블슈팅 가이드
- 비상 연락망 업데이트

## 8. 위험 관리

### 8.1 식별된 위험
| 위험 | 발생 확률 | 영향도 | 대응 방안 |
|------|-----------|--------|-----------|
| 네트워크 단절 | 낮음 | 높음 | 이중화 네트워크 구성 |
| 데이터 손실 | 매우 낮음 | 매우 높음 | 실시간 백업, 트랜잭션 로그 |
| 서비스 중단 | 중간 | 높음 | 롤백 계획, 병렬 운영 |
| 성능 저하 | 중간 | 중간 | 리소스 모니터링, 스케일업 |

### 8.2 비상 연락망
| 역할 | 담당자 | 연락처 | 비고 |
|------|--------|--------|------|
| 프로젝트 관리자 | - | - | 주담당 |
| DBA | - | - | DB 이슈 |
| 개발자 | - | - | 애플리케이션 |
| 네트워크 관리자 | - | - | 네트워크/인프라 |

## 9. 체크리스트

### 9.1 이관 전 체크리스트
- [ ] 전체 시스템 백업 완료
- [ ] 서버 OS 및 Docker 설치 완료
- [ ] 네트워크 통신 테스트 완료
- [ ] 보안 설정 완료
- [ ] 롤백 계획 수립
- [ ] 비상 연락망 확인

### 9.2 이관 중 체크리스트
- [ ] Database Server 구성 완료
- [ ] Backend Server 구성 완료
- [ ] Scheduler Server 구성 완료
- [ ] 데이터 마이그레이션 완료
- [ ] 서비스 연동 테스트 완료
- [ ] 성능 테스트 완료

### 9.3 이관 후 체크리스트
- [ ] 모든 서비스 정상 작동
- [ ] 모니터링 대시보드 정상
- [ ] 백업 스케줄 설정
- [ ] 문서화 완료
- [ ] 인수인계 완료

## 10. 자동화 스크립트

### 10.1 서버 초기화 스크립트
```bash
#!/bin/bash
# setup_server.sh

# 색상 코드
RED='\033[0;31m'
GREEN='\033[0;32m'
NC='\033[0m'

echo -e "${GREEN}Starting server setup...${NC}"

# 시스템 업데이트
echo "Updating system..."
dnf update -y

# Docker 설치
echo "Installing Docker..."
dnf config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
dnf install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin
systemctl start docker
systemctl enable docker

# 방화벽 설정
echo "Configuring firewall..."
firewall-cmd --permanent --add-service=http
firewall-cmd --permanent --add-service=https
firewall-cmd --reload

# 디렉토리 생성
mkdir -p /opt/stock-trading
mkdir -p /var/log/stock-trading

echo -e "${GREEN}Server setup completed!${NC}"
```

### 10.2 헬스체크 스크립트
```bash
#!/bin/bash
# health_check.sh

# 서비스 상태 확인
check_service() {
    local service=$1
    local url=$2

    if curl -f -s -o /dev/null "$url"; then
        echo "✅ $service is healthy"
        return 0
    else
        echo "❌ $service is down"
        return 1
    fi
}

# Database Server
check_service "PostgreSQL" "http://192.168.219.103:5432"
check_service "Redis" "http://192.168.219.103:6379"
check_service "InfluxDB" "http://192.168.219.103:8086/health"

# Backend Server
check_service "Backend API" "http://192.168.219.102:8000/health"

# Scheduler Server
check_service "Airflow" "http://192.168.219.101:8080/health"
check_service "Grafana" "http://192.168.219.101:3000/api/health"
```

### 10.3 백업 스크립트
```bash
#!/bin/bash
# backup.sh

BACKUP_DIR="/backup/$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

# PostgreSQL 백업
echo "Backing up PostgreSQL..."
docker exec stock-db pg_dumpall -U admin | gzip > $BACKUP_DIR/postgres.sql.gz

# Redis 백업
echo "Backing up Redis..."
docker exec stock-redis redis-cli BGSAVE
sleep 5
docker cp stock-redis:/data/dump.rdb $BACKUP_DIR/redis.rdb

# InfluxDB 백업
echo "Backing up InfluxDB..."
docker exec stock-influxdb influx backup /tmp/backup -t my-super-secret-auth-token
docker cp stock-influxdb:/tmp/backup $BACKUP_DIR/influxdb

echo "Backup completed: $BACKUP_DIR"
```

## 11. 주의사항

### 11.1 보안 관련
- 모든 비밀번호는 환경 변수로 관리
- SSL 인증서 적용 필수
- 방화벽 규칙 최소 권한 원칙

### 11.2 데이터 관련
- 이관 중 데이터 수집 중단
- 트랜잭션 로그 보관
- 증분 백업 활용

### 11.3 성능 관련
- 네트워크 대역폭 사전 확인
- 디스크 I/O 모니터링
- CPU/Memory 사용률 추적

## 12. 이관 완료 기준

### 12.1 기능 검증
- [x] 모든 API 엔드포인트 정상 응답
- [x] 데이터 수집 자동화 작동
- [x] 사용자 인증/권한 정상
- [x] 대시보드 정상 표시

### 12.2 성능 기준
- API 평균 응답시간 < 200ms
- 데이터베이스 쿼리 시간 < 100ms
- 시스템 가용성 > 99.9%

### 12.3 운영 준비
- [x] 모니터링 시스템 구축
- [x] 백업 자동화 설정
- [x] 알림 시스템 구성
- [x] 문서화 완료

## 부록 A: 트러블슈팅 가이드

### 문제: Docker 컨테이너가 시작되지 않음
```bash
# 로그 확인
docker logs <container_name>

# 권한 문제 해결
chmod -R 755 /opt/stock-trading
chown -R docker:docker /opt/stock-trading

# Docker 재시작
systemctl restart docker
```

### 문제: 데이터베이스 연결 실패
```bash
# 네트워크 확인
ping 192.168.219.103
telnet 192.168.219.103 5432

# PostgreSQL 설정 확인
docker exec stock-db cat /var/lib/postgresql/data/postgresql.conf | grep listen_addresses
docker exec stock-db cat /var/lib/postgresql/data/pg_hba.conf

# 방화벽 확인
firewall-cmd --list-all
```

### 문제: 성능 저하
```bash
# 리소스 사용량 확인
docker stats

# 로그 레벨 조정
export LOG_LEVEL=WARNING

# 캐시 초기화
docker exec stock-redis redis-cli FLUSHALL
```

## 부록 B: 명령어 참조

### Docker 관련
```bash
# 컨테이너 목록
docker ps -a

# 로그 보기
docker logs -f <container_name>

# 컨테이너 재시작
docker restart <container_name>

# 컨테이너 셸 접속
docker exec -it <container_name> /bin/bash

# 이미지 빌드
docker-compose build --no-cache

# 서비스 시작/중지
docker-compose up -d
docker-compose down
```

### 시스템 모니터링
```bash
# CPU/Memory 사용량
top -b -n 1

# 디스크 사용량
df -h

# 네트워크 상태
netstat -tuln

# 프로세스 확인
ps aux | grep docker
```

## 부록 C: 설정 파일 템플릿

### .env 파일 템플릿
```env
# Database
DB_HOST=192.168.219.103
DB_PORT=5432
DB_NAME=stocktrading
DB_USER=admin
DB_PASSWORD=secure_password_here

# Redis
REDIS_HOST=192.168.219.103
REDIS_PORT=6379
REDIS_PASSWORD=

# InfluxDB
INFLUX_HOST=192.168.219.103
INFLUX_PORT=8086
INFLUX_TOKEN=my-super-secret-auth-token

# Application
JWT_SECRET=change_this_to_random_secret
DEBUG=False
LOG_LEVEL=INFO
```

### systemd 서비스 파일
```ini
[Unit]
Description=Stock Trading System
After=docker.service
Requires=docker.service

[Service]
Type=oneshot
RemainAfterExit=true
WorkingDirectory=/opt/stock-trading
ExecStart=/usr/bin/docker-compose up -d
ExecStop=/usr/bin/docker-compose down
TimeoutStartSec=0

[Install]
WantedBy=multi-user.target
```

---

**문서 버전**: 1.0
**작성일**: 2025년 10월 7일
**최종 수정일**: 2025년 10월 7일
**작성자**: System Administrator
**검토자**: -
**승인자**: -